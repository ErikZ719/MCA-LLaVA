# MCA-LLaVA: Manhattan Causal Attention for Reducing Hallucination in Large Vision-Language Models [ACMM MM25]
The information flow of MCA-LLaVA is follows:
![image](https://github.com/ErikZ719/MCA-LLaVA/blob/main/information-flow.png)

The difference of MCA-LLaVA with CCA-LLaVA and LLaVA is follows:

![image](https://github.com/ErikZ719/MCA-LLaVA/blob/main/Manhattan-Causal-Masking.png)


## Citation
```bibtex
@article{zhaoMCA,
  title={MCA-LLaVA: Manhattan Causal Attention for Reducing Hallucination in Large Vision-Language Models},
  author={Zhao, Qiyan and  Zhang, Xiaofeng and Li, yiheng and Xing, Yun and Yuan Xiaosong and Tang, Feilong and Fan, Sinan and Chen, Xuhang and Zhang, Xuyao and Wang, Dahan},
  journal={The 33rd ACM International Conference on Multimedia},
  year={2025},
  url={https://doi.org/10.1145/3746027.3755271}, 
}
```
## Acknowledgement

This repo is built on [LLaVA](https://github.com/haotian-liu/LLaVA) (models) and [CCA-LLaVA]([https://github.com/pkunlp-icler/FastV](https://github.com/xing0047/cca-llava)) . Many thanks for their efforts. The use of our code should also follow the original licenses.
